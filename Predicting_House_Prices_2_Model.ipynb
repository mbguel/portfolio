{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35_ds_dt_16/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import skew\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Scoring stuff\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error, r2_score\n",
    "\n",
    "# Import model selection tools\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Import models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "import xgboost as xgb # XGBRegressor\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "trainY = train[['SalePrice']] # Creating a trainY dataframe\n",
    "train_IDs = train.Id\n",
    "test_IDs = test.Id\n",
    "\n",
    "# Dropping ID\n",
    "train.drop('Id', axis = 1, inplace = True) \n",
    "test.drop('Id', axis = 1, inplace = True)\n",
    "\n",
    "# Dropping SalePrice\n",
    "train.drop('SalePrice', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_train(df):\n",
    "    imputedColumns = ['PoolQC', 'MiscFeature', 'Alley', 'Fence',\n",
    "                  'FireplaceQu', 'GarageType', 'GarageFinish',\n",
    "                  'GarageQual', 'GarageCond', \"BsmtFinType2\",\n",
    "                  \"BsmtExposure\", \"BsmtFinType1\", \"BsmtCond\",\n",
    "                  \"BsmtQual\", \"MasVnrType\"] \n",
    "    \n",
    "    for col in imputedColumns:\n",
    "        df[col] = df[col].fillna('None')\n",
    "        \n",
    "    # Only a few missing values in the training set for these two columns.\n",
    "    # Using 0, since if there is no garage, there is no year built. If no masonry veneer, there will be no area.\n",
    "    df['GarageYrBlt'] = df['GarageYrBlt'].fillna(0)\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "\n",
    "\n",
    "    # Only 1 missing value in the training set. Imputing most common value for 'Electrical' which is SBrkr\n",
    "    df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])\n",
    "    df['LotFrontage'] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "### Missing stuff in test dataset section:\n",
    "def impute_missing_test(df):\n",
    "    \n",
    "# Imputing zero for columns that use numbers as measures (such as basement in square feet [BsmtFinSF])\n",
    "    zero_cols = ['GarageYrBlt', 'GarageArea', 'GarageCars',\n",
    "                 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                 'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "    \n",
    "    for col in zero_cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # Filling in the missing LotFrontage, accounts for 15% of missing data\n",
    "    df['LotFrontage'] = df.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "    modeCols = ['MSZoning','Exterior1st', 'Exterior2nd', 'SaleType', 'Utilities', 'KitchenQual']\n",
    "    # There are only a few missing values for these columns, so imputing with the mode.\n",
    "    for col in modeCols:\n",
    "        df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "    # NA probably means no subclass\n",
    "    df['MSSubClass'] = df['MSSubClass'].fillna(\"None\")\n",
    "    # Functional - data dictionary says assume Typical\n",
    "    df['Functional'] = df['Functional'].fillna(\"Typ\")  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass     0\n",
       "MSZoning       0\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_missing_train(train)\n",
    "train.isnull().sum()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass     0\n",
       "MSZoning       0\n",
       "LotFrontage    0\n",
       "LotArea        0\n",
       "Street         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impute_missing_train(test)\n",
    "impute_missing_test(test)\n",
    "test.isnull().sum()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying mathematical transformations to dataset\n",
    "[Source](https://www.kaggle.com/mymkyt/simple-lasso-public-score-0-12102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df):\n",
    "    # Taking features that are not objects, which means either int or float.\n",
    "    numeric_feats = df.dtypes[df.dtypes != \"object\"].index\n",
    "\n",
    "    # Calculating skew, keeping numerical features to be transformed whose skew is > 0.75\n",
    "    skewed_feats = df[numeric_feats].apply(lambda x: skew(x)) #compute skewness\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.75]\n",
    "    skewed_feats = skewed_feats.index\n",
    "    \n",
    "    df[skewed_feats] = np.log1p(df[skewed_feats])\n",
    "    \n",
    "#     df = pd.get_dummies(df)\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# LABEL ENCODER FUNCTION\n",
    "def label_encoder(df):\n",
    "    df_object = df.select_dtypes(include=['object']) # Taking the categorical columns only\n",
    "    categorical_Cols = list(df_object.columns) # Inputting the categorical columns into a list\n",
    "\n",
    "    # process columns, apply LabelEncoder to categorical features\n",
    "    for c in categorical_Cols:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(df[c].values)) \n",
    "        df[c] = lbl.transform(list(df[c].values))\n",
    "\n",
    "    # shape        \n",
    "    print('Shape all_data: {}'.format(df.shape))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dataset transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (1460, 79)\n"
     ]
    }
   ],
   "source": [
    "w = transform(train)\n",
    "w = label_encoder(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape all_data: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "w2 = transform(test)\n",
    "w2 = label_encoder(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1460, 79)\n",
      "Test shape: (1459, 79)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape:\", w.shape)\n",
    "print(\"Test shape:\", w2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RMSE(df):\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "    num_folds = 5\n",
    "    seed = 10\n",
    "    kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    models = []\n",
    "\n",
    "    models.append( ('LinearRegression', LinearRegression()) )\n",
    "    models.append( ('RandomForestRegressor', RandomForestRegressor(random_state = seed)) )\n",
    "    models.append( ('GradientBoostingRegressor', GradientBoostingRegressor(random_state = seed)) )\n",
    "    models.append( ('Lasso', Lasso(random_state = seed)) )\n",
    "    models.append( ('Ridge', Ridge(random_state = seed)) ) \n",
    "    models.append( ('ElasticNet', ElasticNet(random_state = seed)) )\n",
    "    models.append( ('XGBRegressor', xgb.XGBRegressor(seed = seed)) )\n",
    "\n",
    "    y = np.log1p(trainY.SalePrice)\n",
    "\n",
    "   \n",
    "    for name, model in models:\n",
    "        kfold = KFold(n_splits = num_folds, random_state = seed)\n",
    "\n",
    "        names.append(name)\n",
    "        model.fit(df, y)\n",
    "\n",
    "        scores = np.sqrt(-cross_val_score(model, df, y, cv = kfold, scoring = scoring))\n",
    "        results.append(scores)\n",
    "\n",
    "        msg = \"{}: RMSE: {} ({})\".format(name, scores.mean(), scores.std())\n",
    "        \n",
    "              \n",
    "        print(msg)\n",
    "        print()\n",
    "                \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: RMSE: 0.1356038110109544 (0.016447017765653837)\n",
      "\n",
      "RandomForestRegressor: RMSE: 0.15043582730432753 (0.008376803401368899)\n",
      "\n",
      "GradientBoostingRegressor: RMSE: 0.12763688213426305 (0.008384282964745533)\n",
      "\n",
      "Lasso: RMSE: 0.2682893719781311 (0.010577842474056123)\n",
      "\n",
      "Ridge: RMSE: 0.13516496946197698 (0.016762635632164576)\n",
      "\n",
      "ElasticNet: RMSE: 0.26454219580925276 (0.010858647898008571)\n",
      "\n",
      "XGBRegressor: RMSE: 0.13081765316459154 (0.009804400274497986)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.11696099,  0.14654425,  0.13453396,  0.11942718,  0.16055268]),\n",
       " array([ 0.14152407,  0.16451594,  0.1495733 ,  0.1426628 ,  0.15390302]),\n",
       " array([ 0.11578586,  0.14020592,  0.13283115,  0.12260762,  0.12675387]),\n",
       " array([ 0.24792768,  0.27478734,  0.27184539,  0.26915009,  0.27773636]),\n",
       " array([ 0.11573729,  0.14623121,  0.13380478,  0.11933849,  0.16071307]),\n",
       " array([ 0.24509993,  0.2716857 ,  0.26434127,  0.26437495,  0.27720913]),\n",
       " array([ 0.11610876,  0.14179439,  0.13809939,  0.12254411,  0.13554162])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submitting Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso = Lasso(alpha=0.0004)\n",
    "seed = 10\n",
    "model = GradientBoostingRegressor(random_state = seed)\n",
    "y = np.log1p(trainY.SalePrice)\n",
    "\n",
    "\n",
    "### prediction\n",
    "model.fit(w, y)\n",
    "\n",
    "preds = np.expm1(model.predict(w2))\n",
    "solution = pd.DataFrame({\"id\": test_IDs, \"SalePrice\":preds})\n",
    "solution.to_csv(\"GBR_v3.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
